
# Delete -------------------------------------------------------------------------------------------------------------------

######################################################  To Ignore  ########################################################
def getNormlizedAllanVariance(dirname):
    allan_df = pd.read_csv(dirname+'\\'+'allan.csv')
    allanNorm_df = allan_df.copy()
    columns = allan_df.columns.to_list()
    freqs = [element for element in columns[11:]]
    #
    normRow = allan_df.loc[0, columns[11:]].values.flatten().tolist()
    repName = allan_df.loc[0, columns[4]]
    powerName = allan_df.loc[0, columns[5]]
    for index, irow in allan_df.iterrows():
        if (index != 0):
            if ( (repName != allan_df.loc[index, columns[4]]) or (powerName != allan_df.loc[index, columns[5]]) ):
                normRow = allan_df.loc[index, columns[11:]].values.flatten().tolist()
                repName = allan_df.loc[index, columns[4]]
                powerName = allan_df.loc[index, columns[5]]
                # The row (index) stay as it is.
            else:
                thisRow = allan_df.loc[index, columns[11:]].values.flatten().tolist()
                normalizedRow = []
                for i in range(0, len(thisRow)):
                    # normalizedRow.append(thisRow[i]/normRow[i])
                    normalizedRow.append(round(thisRow[i]/normRow[i], 2))
                allanNorm_df.loc[index,freqs] = normalizedRow
    # The for loop is over. Save all the data.
    allanNorm_df.to_csv(dirname+'\\allan_norm.csv', index=False, encoding='utf-8')
    del allan_df
    del allanNorm_df
######################################################   To Ignore ########################################################

    # getNormlizedByCustomFreq("..\\Results\\2023_03_23_15_29_25_116512_Eyal & Alex\\", '1475')
    # getNormlizedAllanVariance(dirname)
    # print("normalize and divide time: {:.2f}".format(time.time()-now))


# def getAnalyzerTransmition(dirname):
    # Analyzer - Clean.###################### Main Idea.
    # This function will get the dir name
    # 1) Read 'clean' & 'analyzer' to df - OK
    # 2) Create clean/empty transmition df
    # 3) Iterate over analyzer dataframe
    #     if: 'analyzer' row same as 'clean' row appand to transmition (hilok mainpulation)
    #     else: update 'clean' row and continue.
    # 4) Save as transmission_analyzer.csv
    # This function result is I/I0.
    # clean_row.to_csv(dirname+'\\clean_row.csv', index=False, encoding='utf-8')
    # analyzer_rows.to_csv(dirname+'\\analyzer_rows.csv', index=False, encoding='utf-8')
    # analyzer_rowsNumber = analyzer_rows.shape[0] # The nuber of the rows of the dataframe.
    # a = analyzer_rows.loc[row,f]
    # b = clean_row.loc[0,f]
    # c = new_row.loc[f]

        # columns = df_A.columns.to_list()
    # if index != -1: # It will take the correspond value from the list.
    #     A = AbsorptionList[index]
    # else: # It will take the last possible value.
    #     A = AbsorptionList[-1]


                #clean_val = (clean_row.loc[0]).to_numpy()
            # print(df_analyzer.iloc[row,10:15])
            # for idx in range(10,len(clean_val)):
                # a = clean_val[idx]
                # df_analyzer.iloc[row,idx] = df_analyzer.iloc[row,idx].apply(lambda val : val - clean_val[idx])
                # df_analyzer[row][idx] = df_analyzer.iloc[row][idx] - clean_val[idx]
                # print(df_analyzer.iloc[row,10:15])     
                # for f in freqs:
                #     a = df_analyzer.iloc[row][f]
                #     b = clean_row.iloc[0][f]
                #     c = a - b
                #df_analyzer[row, df_analyzer.columns.get_loc(f)] = (df_analyzer.iloc[row][f] - clean_row.iloc[0][f])
                # df_analyzer[row][f] = df_analyzer.iloc[row][f] - clean_row.iloc[0][f]
                #print("df_analyzer[row][f]=",df_analyzer.iloc[row][f]," and c=",c)
            #df_analyzer.to_csv(dirname+'\\transmittance.csv', index=False, encoding='utf-8')

            # clean_row.to_csv(dirname+'\\clean_row.csv', index=False, encoding='utf-8')       
                # clean_val = (clean_row.iloc[0,10:]).to_numpy()
                #a = df_analyzer.iloc[row][f]
                #b = clean_row.iloc[0][f]
                #c = a - b
                #a = len(new_row)
            #df_analyzer[row][10:] = new_row
            
# def finalCSVFile():
#     # This function create a new csv file that contain additional one column of the concentrations and one column of the chosen waveguide. 
#     #allResults_df = pd.DataFrame(columns=['Date', 'Comment', 'CF',	'SPAN',	'REP_RATE',	'POWER', 'Sens','Res', 'Interval', 'SAMPLINGS_NUMBER']+freqs_columns)
#     None


# def getAnalyzerTransmition(dirname, v=1):
#     try:
#         df_clean = pd.read_csv(dirname+'\\'+'clean.csv')
#         df_analyzer = pd.read_csv(dirname+'\\analyzer.csv')
#     except:
#         return False
    
#     ###### Here is the normalize

#     #
#     df_columns = df_clean.columns.to_list()
#     freqs = [element for element in df_columns[10:]]
#     REP_list = df_clean['REP_RATE'].unique().tolist()
#     POWER_list = df_clean['POWER'].unique().tolist()
#     r = None
#     p = None
#     clean_row_number = df_clean.shape[0]
#     for row in range(df_analyzer.shape[0]):
#         if ( df_analyzer.iloc[row]['REP_RATE'] != r or df_analyzer.iloc[row]['POWER'] != p ):
#             r = df_analyzer.iloc[row]['REP_RATE']
#             p = df_analyzer.iloc[row]['POWER']
#             clean_row = df_clean.iloc[clean_row_number,10:]
#             clean_row_number = clean_row_number + 1
#         df_clean[row,10:] = clean_row
#     df_transmittance = df_analyzer[freqs].subtract(df_clean[freqs])
#     df_transmittance.to_csv(dirname+'\\transmittance.csv', index=False, encoding='utf-8')
#     return df_transmittance
##########################################################################################3
        # df_transmittance = pd.DataFrame(columns=df_columns)
        # new_row = []
        # for idx in range(10):
        #     new_row.append(df_analyzer.iloc[row][idx])        
        #     clean_row = df_clean.loc[(df_clean['REP_RATE'] == r) & (df_clean['POWER'] == p)]
        # for f in freqs:
        #     new_row.append( df_analyzer.iloc[row][f] - clean_row.iloc[0][f] )
        # df_transmittance.loc[len(df_transmittance)] = new_row

    # if (v == 2):
    #     # Version 2:
    #     columns = df_clean.columns.to_list()
    #     freqs = [element for element in columns[10:]]
    #     REP_list = df_clean['REP_RATE'].unique().tolist()
    #     POWER_list = df_clean['POWER'].unique().tolist()
    #     df_transmittance = pd.DataFrame(columns)
    #     df_transmittance.to_csv(dirname+'\\transmittance.csv', index=False, encoding='utf-8')
    #     for r in REP_list:
    #         for p in POWER_list:
    #             clean_row = df_clean.loc[(df_clean['REP_RATE'] == r) & (df_clean['POWER'] == p)].iloc[0]
    #             analyzer_rows = df_analyzer.loc[(df_analyzer['REP_RATE'] == r) & (df_analyzer['POWER'] == p)]
    #             for row in range(analyzer_rows.shape[0]):
    #                 new_row = analyzer_rows.iloc[row]
    #                 for f in freqs:
    #                     new_row.loc[f] = new_row.loc[f] - clean_row.loc[f]
    #                 df_transmittance = df_transmittance.append(pd.Series(new_row, index = columns), ignore_index=True)
    #     df_transmittance.to_csv(dirname+'\\transmittance.csv', index=False, encoding='utf-8')
    #     return df_transmittance

    #REP_list = df_clean['REP_RATE'].unique().tolist()
    #POWER_list = df_clean['POWER'].unique().tolist()


# def getAnalyzerTransmition(dirname, to_norm=False, waveLength = '1550'):
#     try:
#         df_clean = pd.read_csv(dirname+'\\'+'clean.csv')
#         df_analyzer = pd.read_csv(dirname+'\\analyzer.csv')
#     except:
#         return False
    
#     ###### Here is the normalize
#     columns = df_clean.columns.to_list()
    
#     if to_norm:
#         wavelengths = [float(element) for element in columns[10:]]
#         distance_from_user = [abs(float(waveLength)-element) for element in wavelengths]
#         real_wavelength_from_user = str(wavelengths[np.argmin(distance_from_user)])
#         # Getting the elemnts of normalizations:
#         norm_vals_clean = df_clean[real_wavelength_from_user]
#         norm_vals_analyzer = df_analyzer[real_wavelength_from_user]

#         # Normalizing both clean and substance CSVs
#         R, _ = df_analyzer.shape
#         for idx in range(0,R):
#             # Iterating over each row and normlizing
#             df_analyzer.iloc[idx,10:] = df_analyzer.iloc[idx,10:].apply(lambda val : val - norm_vals_analyzer[idx])
#         R, _ = df_clean.shape
#         for idx in range(0,R):
#             # Iterating over each row and normlizing
#             df_clean.iloc[idx,10:] = df_clean.iloc[idx,10:].apply(lambda val : val - norm_vals_clean[idx])
    
#     ## [dB], [dBm] --> [dB]

#     df_columns = columns
#     freqs = [element for element in df_columns[10:]]
#     r = None
#     p = None
#     df_transmittance = df_analyzer.copy()
#     df_clean_multipled = pd.DataFrame(columns=df_columns)
#     for idx, row in df_analyzer.iterrows():
#         if ( row['REP_RATE'] != r or row['POWER'] != p ):
#             r = row['REP_RATE']
#             p = row['POWER']
#             clean_row = df_clean.loc[(df_clean['REP_RATE'] == r) & (df_clean['POWER'] == p)]
#         df_clean_multipled = df_clean_multipled.append(clean_row)
#     df_clean_multipled = df_clean_multipled.reset_index(drop=True)
#     df_transmittance[freqs] = df_transmittance[freqs].subtract(df_clean_multipled[freqs])
#     df_transmittance.to_csv(dirname+'\\transmittance.csv', index=False, encoding='utf-8')
#     return df_transmittance
